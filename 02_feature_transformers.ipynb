{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10981070,"sourceType":"datasetVersion","datasetId":6833808},{"sourceId":10981091,"sourceType":"datasetVersion","datasetId":6833826}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn as sk\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:02:33.542820Z","iopub.execute_input":"2025-03-10T15:02:33.543132Z","iopub.status.idle":"2025-03-10T15:02:33.548128Z","shell.execute_reply.started":"2025-03-10T15:02:33.543109Z","shell.execute_reply":"2025-03-10T15:02:33.547034Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# Charger les données\ndata = pd.read_csv(\"/kaggle/input/full-set-complete-v2-csv/full_set_complete_v2.csv\").drop(columns=[\"Index\"])\ndata = data.sort_values(by=[\"patient_id\", \"age\"])  # Trier par patient_id et âge\n\n\ndata['patient_id'] = data['patient_id'].astype(int)\n# Ajouter l'index de mesure pour chaque patient\ndata['index_measure'] = data.groupby('patient_id').cumcount() + 1\nprint(data.shape)\n\nfixed_features = ['cohort', 'sexM', 'gene', 'age_at_diagnosis']\ntemp_features = ['age', 'ledd', 'time_since_intake_on', 'time_since_intake_off', 'on', 'off', 'on_off_ratio', \n                 'off_cumavg', 'on_cumavg', 'off_lag1', 'on_lag1', 'off_ewma', 'index_measure']\nfeatures = fixed_features + temp_features\n\n# Normalisation des variables temporelles\nscaler = StandardScaler()\ndata[features] = scaler.fit_transform(data[features])\ndata.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:24.250711Z","iopub.execute_input":"2025-03-10T15:13:24.251075Z","iopub.status.idle":"2025-03-10T15:13:24.509254Z","shell.execute_reply.started":"2025-03-10T15:13:24.251049Z","shell.execute_reply":"2025-03-10T15:13:24.508159Z"}},"outputs":[{"name":"stdout","text":"(79275, 18)\n","output_type":"stream"},{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"       patient_id    cohort      sexM      gene  age_at_diagnosis       age  \\\n61660           0 -0.349128  0.812747  0.612279         -0.196429 -0.366380   \n61661           0 -0.349128  0.812747  0.612279         -0.196429 -0.296457   \n\n           ledd  time_since_intake_on  time_since_intake_off        on  \\\n61660 -0.455251              1.989774               0.153672 -0.215453   \n61661 -0.203599              1.090589               0.178718 -0.790243   \n\n            off  on_off_ratio  off_cumavg  on_cumavg  off_lag1   on_lag1  \\\n61660  0.371074     -0.279301    0.684973  -0.007987 -0.474057 -1.142693   \n61661 -0.080819     -0.341219    0.428951  -0.361674  0.432530 -0.170967   \n\n       off_ewma  index_measure  \n61660  0.433334      -1.289041  \n61661  0.119591      -0.985394  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>sexM</th>\n      <th>gene</th>\n      <th>age_at_diagnosis</th>\n      <th>age</th>\n      <th>ledd</th>\n      <th>time_since_intake_on</th>\n      <th>time_since_intake_off</th>\n      <th>on</th>\n      <th>off</th>\n      <th>on_off_ratio</th>\n      <th>off_cumavg</th>\n      <th>on_cumavg</th>\n      <th>off_lag1</th>\n      <th>on_lag1</th>\n      <th>off_ewma</th>\n      <th>index_measure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>61660</th>\n      <td>0</td>\n      <td>-0.349128</td>\n      <td>0.812747</td>\n      <td>0.612279</td>\n      <td>-0.196429</td>\n      <td>-0.366380</td>\n      <td>-0.455251</td>\n      <td>1.989774</td>\n      <td>0.153672</td>\n      <td>-0.215453</td>\n      <td>0.371074</td>\n      <td>-0.279301</td>\n      <td>0.684973</td>\n      <td>-0.007987</td>\n      <td>-0.474057</td>\n      <td>-1.142693</td>\n      <td>0.433334</td>\n      <td>-1.289041</td>\n    </tr>\n    <tr>\n      <th>61661</th>\n      <td>0</td>\n      <td>-0.349128</td>\n      <td>0.812747</td>\n      <td>0.612279</td>\n      <td>-0.196429</td>\n      <td>-0.296457</td>\n      <td>-0.203599</td>\n      <td>1.090589</td>\n      <td>0.178718</td>\n      <td>-0.790243</td>\n      <td>-0.080819</td>\n      <td>-0.341219</td>\n      <td>0.428951</td>\n      <td>-0.361674</td>\n      <td>0.432530</td>\n      <td>-0.170967</td>\n      <td>0.119591</td>\n      <td>-0.985394</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"Y_train= pd.read_csv('/kaggle/input/datasets-row/y_train_lXj6X5y.csv',index_col=0)\nX_train= pd.read_csv('/kaggle/input/datasets-row/X_train_6ZIKlTY.csv', index_col=0)\nX_test= pd.read_csv('/kaggle/input/datasets-row/X_test_oiZ2ukx.csv',index_col=0)\nX_test.index = X_test.index + X_train.shape[0]  # Décale les index de X_test\n\nprint(Y_train.shape)\nX_train_filled = data.loc[X_train.index]\nY_train = Y_train\nprint(X_train_filled.shape)\nX_train_filled = pd.concat([X_train_filled, Y_train], axis = 1)\nX_train_filled.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:28.264455Z","iopub.execute_input":"2025-03-10T15:13:28.264799Z","iopub.status.idle":"2025-03-10T15:13:28.442648Z","shell.execute_reply.started":"2025-03-10T15:13:28.264770Z","shell.execute_reply":"2025-03-10T15:13:28.441527Z"}},"outputs":[{"name":"stdout","text":"(55603, 1)\n(55603, 18)\n","output_type":"stream"},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"       patient_id    cohort      sexM      gene  age_at_diagnosis       age  \\\nIndex                                                                         \n0            3332 -0.349128 -1.230396 -0.579843         -0.758273 -0.899541   \n1            3332 -0.349128 -1.230396 -0.579843         -0.758273 -0.820878   \n2            3332 -0.349128 -1.230396 -0.579843         -0.758273 -0.742215   \n\n           ledd  time_since_intake_on  time_since_intake_off        on  \\\nIndex                                                                    \n0      0.077090             -0.033392               0.503441 -1.173437   \n1      0.362618             -0.033392               2.604987 -0.694445   \n2      0.609431             -0.820179               0.576582 -1.269235   \n\n            off  on_off_ratio  off_cumavg  on_cumavg  off_lag1   on_lag1  \\\nIndex                                                                      \n0      0.520783     -0.470384    0.854610  -1.186945  0.035112 -0.559846   \n1      0.859732     -0.408921    1.046644  -0.892206  0.583761 -1.143164   \n2      0.586436     -0.490273    1.007430  -1.029751  0.926159 -0.657065   \n\n       off_ewma  index_measure  target  \nIndex                                   \n0      0.589245      -1.289041    34.7  \n1      0.824572      -0.985394    38.1  \n2      0.713269      -0.681747    41.6  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>sexM</th>\n      <th>gene</th>\n      <th>age_at_diagnosis</th>\n      <th>age</th>\n      <th>ledd</th>\n      <th>time_since_intake_on</th>\n      <th>time_since_intake_off</th>\n      <th>on</th>\n      <th>off</th>\n      <th>on_off_ratio</th>\n      <th>off_cumavg</th>\n      <th>on_cumavg</th>\n      <th>off_lag1</th>\n      <th>on_lag1</th>\n      <th>off_ewma</th>\n      <th>index_measure</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>Index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3332</td>\n      <td>-0.349128</td>\n      <td>-1.230396</td>\n      <td>-0.579843</td>\n      <td>-0.758273</td>\n      <td>-0.899541</td>\n      <td>0.077090</td>\n      <td>-0.033392</td>\n      <td>0.503441</td>\n      <td>-1.173437</td>\n      <td>0.520783</td>\n      <td>-0.470384</td>\n      <td>0.854610</td>\n      <td>-1.186945</td>\n      <td>0.035112</td>\n      <td>-0.559846</td>\n      <td>0.589245</td>\n      <td>-1.289041</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3332</td>\n      <td>-0.349128</td>\n      <td>-1.230396</td>\n      <td>-0.579843</td>\n      <td>-0.758273</td>\n      <td>-0.820878</td>\n      <td>0.362618</td>\n      <td>-0.033392</td>\n      <td>2.604987</td>\n      <td>-0.694445</td>\n      <td>0.859732</td>\n      <td>-0.408921</td>\n      <td>1.046644</td>\n      <td>-0.892206</td>\n      <td>0.583761</td>\n      <td>-1.143164</td>\n      <td>0.824572</td>\n      <td>-0.985394</td>\n      <td>38.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3332</td>\n      <td>-0.349128</td>\n      <td>-1.230396</td>\n      <td>-0.579843</td>\n      <td>-0.758273</td>\n      <td>-0.742215</td>\n      <td>0.609431</td>\n      <td>-0.820179</td>\n      <td>0.576582</td>\n      <td>-1.269235</td>\n      <td>0.586436</td>\n      <td>-0.490273</td>\n      <td>1.007430</td>\n      <td>-1.029751</td>\n      <td>0.926159</td>\n      <td>-0.657065</td>\n      <td>0.713269</td>\n      <td>-0.681747</td>\n      <td>41.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, Dataset\n\nclass PatientDataset(Dataset):\n    def __init__(self, df, fixed_features, temp_features, target_col):\n        self.df = df\n        self.fixed_features = fixed_features\n        self.temp_features = temp_features\n        self.target_col = target_col\n\n        # Liste des (patient_id, index) pour chaque ligne du dataset\n        self.index_mapping = [(pid, i) for pid, group in df.groupby(\"patient_id\") for i in range(len(group))]\n\n    def __len__(self):\n        return len(self.index_mapping)\n\n    def __getitem__(self, idx):\n        patient_id, t = self.index_mapping[idx]\n        patient_data = self.df[self.df[\"patient_id\"] == patient_id]\n\n        # Extraire les variables fixes (constantes pour un patient)\n        x_fixed = torch.tensor(patient_data[self.fixed_features].iloc[0].values, dtype=torch.float32)\n\n        # Extraire les variables temporelles jusqu'à l'instant t (t premières lignes)\n        x_temp = torch.tensor(patient_data[self.temp_features].iloc[:t].values, dtype=torch.float32)\n\n        # Si target_col est défini, on récupère la target\n        if self.target_col is not None:\n            y_target = torch.tensor(patient_data[self.target_col].iloc[t], dtype=torch.float32)\n            return x_fixed, x_temp, y_target\n        else:\n            return x_fixed, x_temp\n\ndef collate_fn(batch):\n    x_fixed_batch, x_temp_batch, y_target_batch = zip(*batch)\n\n    x_fixed_batch = torch.stack(x_fixed_batch)  # (batch_size, num_fixed_features)\n    y_target_batch = torch.tensor(y_target_batch, dtype=torch.float32)  # (batch_size,)\n\n    x_temp_batch = pad_sequence(x_temp_batch, batch_first=True, padding_value=0)  # (batch_size, max_seq_len, num_temp_features)\n\n    # Création du mask (True si padding)\n    mask = (x_temp_batch == 0).all(dim=2)  # (batch_size, max_seq_len)\n\n    return x_fixed_batch, x_temp_batch, y_target_batch, mask\n\ndataset = PatientDataset(df=X_train_filled, fixed_features=fixed_features, temp_features=temp_features, target_col=\"target\")\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n\n# Vérification\n#next(iter(dataloader))  # Test pour voir si ça fonctionne\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:32.549274Z","iopub.execute_input":"2025-03-10T15:13:32.549619Z","iopub.status.idle":"2025-03-10T15:13:32.807184Z","shell.execute_reply.started":"2025-03-10T15:13:32.549592Z","shell.execute_reply":"2025-03-10T15:13:32.806546Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass TimeSeriesPredictor(nn.Module):\n    def __init__(self, num_temp_features, num_fixed_features, encoding_dim=16, num_heads=4, hidden_dim=64):\n        super(TimeSeriesPredictor, self).__init__()\n\n        # Embedding des variables fixes\n        self.encoder_fixed = nn.Sequential(\n            nn.Linear(num_fixed_features, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, encoding_dim)\n        )\n\n        # Embedding temporel via Transformer\n        self.temporal_embedding = nn.Linear(num_temp_features, hidden_dim)\n        self.transformer_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=2)\n        self.encoder_fc = nn.Linear(hidden_dim, encoding_dim)\n\n        # FiLM pour injecter les variables fixes\n        self.film_scale = nn.Linear(encoding_dim, hidden_dim)  # Gamma\n        self.film_shift = nn.Linear(encoding_dim, hidden_dim)  # Beta\n\n        # Prédiction de la target\n        self.target_pred_layer_1 = nn.Sequential(\n            nn.Linear(2 * encoding_dim, hidden_dim),  # Concaténer fixed et temp encodés\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim)  # Changer la sortie pour qu'elle soit de taille hidden_dim (64)\n        )\n\n        \n        self.target_pred_layer_2 = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim),  # Concaténer fixed et temp encodés\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)  # Sortie = 1 seule valeur\n        )\n\n    def forward(self, x_fixed, x_temp, mask=None):\n        # **Encoder les variables fixes**\n        encoded_fixed = self.encoder_fixed(x_fixed)  # (batch, encoding_dim)\n\n        # **Encoder les variables temporelles**\n        temp_embedded = self.temporal_embedding(x_temp)  # (batch, seq_len, hidden_dim)\n        \n        # **Appliquer le Transformer avec un mask (pour ignorer le padding)**\n        if mask is not None:\n            temp_encoded = self.transformer(temp_embedded, src_key_padding_mask=mask)  # (batch, seq_len, hidden_dim)\n        else:\n            temp_encoded = self.transformer(temp_embedded)\n\n        # **Récupérer la dernière représentation non-pad**\n        seq_lengths = (~mask).sum(dim=1) - 1  # Index du dernier vrai token\n        encoded_temp = torch.stack([temp_encoded[i, seq_lengths[i], :] for i in range(temp_encoded.size(0))])  # (batch, hidden_dim)\n        encoded_temp = self.encoder_fc(encoded_temp)  # (batch, encoding_dim)\n\n        # **Générer FiLM parameters (scale et shift)**\n        gamma = self.film_scale(encoded_fixed).unsqueeze(1)  # (batch, 1, hidden_dim)\n        beta = self.film_shift(encoded_fixed).unsqueeze(1)   # (batch, 1, hidden_dim)\n\n        # **Modifier les représentations temporelles avec FiLM**\n        temp_encoded = gamma * temp_encoded + beta  # (batch, seq_len, hidden_dim)\n\n        # **Concaténer encoded_fixed et encoded_temp pour la prédiction**\n        final_representation = torch.cat((encoded_fixed, encoded_temp), dim=1)\n\n        # **Prédiction de la target**\n        target_pred = self.target_pred_layer_1(final_representation).squeeze(1)  # (batch,)\n        target_pred = self.target_pred_layer_2(target_pred).squeeze(1)  # (batch,)\n\n        return target_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:34.374391Z","iopub.execute_input":"2025-03-10T15:13:34.374680Z","iopub.status.idle":"2025-03-10T15:13:34.383706Z","shell.execute_reply.started":"2025-03-10T15:13:34.374657Z","shell.execute_reply":"2025-03-10T15:13:34.382711Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"import torch.optim as optim\n\n# Définir les paramètres\nnum_temp_features = len(temp_features)\nnum_fixed_features = len(fixed_features)\n\n# Initialiser le modèle\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TimeSeriesPredictor(num_temp_features, num_fixed_features).to(device)\nmodel.load_state_dict(torch.load(\"best_model_3.pth\"))\n\n# Définir la perte et l'optimiseur\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n# Boucle d'entraînement\nnum_epochs = 20\nbest_loss = float(\"inf\")\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n\n    for x_fixed, x_temp, y_target, mask in dataloader:  # On récupère aussi le mask !\n        # Envoyer sur GPU si dispo\n        x_fixed, x_temp, y_target, mask = x_fixed.to(device), x_temp.to(device), y_target.to(device), mask.to(device)\n\n        # Reset gradients\n        optimizer.zero_grad()\n\n        # Forward (ajout du mask !)\n        y_pred = model(x_fixed, x_temp, mask)\n\n        # Calcul de la perte\n        loss = criterion(y_pred, y_target)\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(dataloader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n\n    # Sauvegarde du meilleur modèle\n    if avg_loss < best_loss:\n        best_loss = avg_loss\n        torch.save(model.state_dict(), \"best_model_3.pth\")\n        print(\"✅ Meilleur modèle sauvegardé !\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:13:47.498076Z","iopub.execute_input":"2025-03-10T15:13:47.498417Z","iopub.status.idle":"2025-03-10T15:27:09.361756Z","shell.execute_reply.started":"2025-03-10T15:13:47.498390Z","shell.execute_reply":"2025-03-10T15:27:09.360464Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-104-cd3e693df772>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_model_3.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20], Loss: 42.6289\n✅ Meilleur modèle sauvegardé !\nEpoch [2/20], Loss: 42.5096\n✅ Meilleur modèle sauvegardé !\nEpoch [3/20], Loss: 42.1597\n✅ Meilleur modèle sauvegardé !\nEpoch [4/20], Loss: 41.8717\n✅ Meilleur modèle sauvegardé !\nEpoch [5/20], Loss: 41.7009\n✅ Meilleur modèle sauvegardé !\nEpoch [6/20], Loss: 41.4844\n✅ Meilleur modèle sauvegardé !\nEpoch [7/20], Loss: 41.4654\n✅ Meilleur modèle sauvegardé !\nEpoch [8/20], Loss: 41.2146\n✅ Meilleur modèle sauvegardé !\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-104-cd3e693df772>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_fixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# On récupère aussi le mask !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Envoyer sur GPU si dispo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_fixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_fixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-102-1c912642e381>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mx_fixed_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_temp_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mx_fixed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fixed_batch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, num_fixed_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0my_target_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_target_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":104},{"cell_type":"markdown","source":"## Inférence sur le testset","metadata":{}},{"cell_type":"code","source":"# Charger le modèle entraîné\nmodel.load_state_dict(torch.load(\"best_model_3.pth\"))\nmodel.eval()  # Mode évaluation\n\n# Charger les données\ndata_for_target = pd.read_csv(\"/kaggle/input/full-set-complete-v2-csv/full_set_complete_v2.csv\").drop(columns=[\"Index\"])\ndata_for_target = data_for_target.sort_values(by=[\"patient_id\", \"age\"])  # Trier par patient_id et âge\n\n\ndata_for_target['patient_id'] = data_for_target['patient_id'].astype(int)\n# Ajouter l'index de mesure pour chaque patient\ndata_for_target['index_measure'] = data_for_target.groupby('patient_id').cumcount() + 1\n\nfixed_features = ['cohort', 'sexM', 'gene', 'age_at_diagnosis']\ntemp_features = ['age', 'ledd', 'time_since_intake_on', 'time_since_intake_off', 'on', 'off', 'on_off_ratio', \n                 'off_cumavg', 'on_cumavg', 'off_lag1', 'on_lag1', 'off_ewma', 'index_measure']\nfeatures = fixed_features + temp_features\n\n# Normalisation des variables temporelles\nscaler = StandardScaler()\ndata[features] = scaler.fit_transform(data[features])\n\ndata_for_target.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:27:12.775017Z","iopub.execute_input":"2025-03-10T15:27:12.775349Z","iopub.status.idle":"2025-03-10T15:27:13.039236Z","shell.execute_reply.started":"2025-03-10T15:27:12.775303Z","shell.execute_reply":"2025-03-10T15:27:13.038423Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-105-1b6d44d8e7b8>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"best_model_3.pth\"))\n","output_type":"stream"},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"       patient_id  cohort  sexM  gene  age_at_diagnosis   age   ledd  \\\n61660           0       0     1     2              54.5  58.2  497.0   \n61661           0       0     1     2              54.5  59.0  549.0   \n61662           0       0     1     2              54.5  59.6  581.0   \n\n       time_since_intake_on  time_since_intake_off    on        off  \\\n61660                   3.7              14.310491  17.0  36.244167   \n61661                   2.9              14.344101  11.0  29.071857   \n61662                   1.1              14.500000  29.0  43.000000   \n\n       on_off_ratio  off_cumavg  on_cumavg   off_lag1    on_lag1   off_ewma  \\\n61660      0.456447   36.244167       17.0  22.000000   7.004841  36.244167   \n61661      0.365791   32.658012       14.0  36.244167  17.000000  31.462627   \n61662      0.659091   36.105341       19.0  29.071857  11.000000  39.154209   \n\n       index_measure  \n61660              1  \n61661              2  \n61662              3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>sexM</th>\n      <th>gene</th>\n      <th>age_at_diagnosis</th>\n      <th>age</th>\n      <th>ledd</th>\n      <th>time_since_intake_on</th>\n      <th>time_since_intake_off</th>\n      <th>on</th>\n      <th>off</th>\n      <th>on_off_ratio</th>\n      <th>off_cumavg</th>\n      <th>on_cumavg</th>\n      <th>off_lag1</th>\n      <th>on_lag1</th>\n      <th>off_ewma</th>\n      <th>index_measure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>61660</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>58.2</td>\n      <td>497.0</td>\n      <td>3.7</td>\n      <td>14.310491</td>\n      <td>17.0</td>\n      <td>36.244167</td>\n      <td>0.456447</td>\n      <td>36.244167</td>\n      <td>17.0</td>\n      <td>22.000000</td>\n      <td>7.004841</td>\n      <td>36.244167</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>61661</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>59.0</td>\n      <td>549.0</td>\n      <td>2.9</td>\n      <td>14.344101</td>\n      <td>11.0</td>\n      <td>29.071857</td>\n      <td>0.365791</td>\n      <td>32.658012</td>\n      <td>14.0</td>\n      <td>36.244167</td>\n      <td>17.000000</td>\n      <td>31.462627</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>61662</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>59.6</td>\n      <td>581.0</td>\n      <td>1.1</td>\n      <td>14.500000</td>\n      <td>29.0</td>\n      <td>43.000000</td>\n      <td>0.659091</td>\n      <td>36.105341</td>\n      <td>19.0</td>\n      <td>29.071857</td>\n      <td>11.000000</td>\n      <td>39.154209</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":105},{"cell_type":"code","source":"class PatientPredictionDataset(Dataset):\n    def __init__(self, df, fixed_features, temp_features):\n        self.df = df\n        self.fixed_features = fixed_features\n        self.temp_features = temp_features\n\n        # Liste des (patient_id, index) pour chaque ligne du dataset\n        self.index_mapping = [(pid, i) for pid, group in df.groupby(\"patient_id\") for i in range(len(group))]\n\n    def __len__(self):\n        return len(self.index_mapping)\n\n    def __getitem__(self, idx):\n        patient_id, t = self.index_mapping[idx]\n        patient_data = self.df[self.df[\"patient_id\"] == patient_id]\n\n        # Extraire les variables fixes (constantes pour un patient)\n        x_fixed = torch.tensor(patient_data[self.fixed_features].iloc[0].values, dtype=torch.float32)\n\n        # Extraire les variables temporelles jusqu'à l'instant t (t premières lignes)\n        x_temp = torch.tensor(patient_data[self.temp_features].iloc[:t].values, dtype=torch.float32)\n\n        return x_fixed, x_temp  # Pas de y_target ici, car tu fais des prédictions\n\ndef collate_fn(batch):\n    x_fixed_batch, x_temp_batch = zip(*batch)\n\n    x_fixed_batch = torch.stack(x_fixed_batch)  # (batch_size, num_fixed_features)\n\n    x_temp_batch = pad_sequence(x_temp_batch, batch_first=True, padding_value=0)  # (batch_size, max_seq_len, num_temp_features)\n\n    # Création du mask (True si padding)\n    mask = (x_temp_batch == 0).all(dim=2)  # (batch_size, max_seq_len)\n\n    return x_fixed_batch, x_temp_batch, mask\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:27:16.775428Z","iopub.execute_input":"2025-03-10T15:27:16.775783Z","iopub.status.idle":"2025-03-10T15:27:16.783015Z","shell.execute_reply.started":"2025-03-10T15:27:16.775757Z","shell.execute_reply":"2025-03-10T15:27:16.781910Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"# Créer un DataLoader pour data_for_target\nprediction_dataset = PatientPredictionDataset(df=data_for_target, fixed_features=fixed_features, temp_features=temp_features)\nprediction_dataloader = DataLoader(prediction_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n#next(iter(prediction_dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:27:19.365990Z","iopub.execute_input":"2025-03-10T15:27:19.366303Z","iopub.status.idle":"2025-03-10T15:27:19.532205Z","shell.execute_reply.started":"2025-03-10T15:27:19.366276Z","shell.execute_reply":"2025-03-10T15:27:19.531414Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"# Effectuer les prédictions\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for x_fixed, x_temp, mask in prediction_dataloader:\n\n        x_fixed, x_temp, mask = x_fixed.to(device), x_temp.to(device), mask.to(device)\n        \n        # Passer les données dans le modèle\n        y_pred = model(x_fixed, x_temp, mask)\n\n        # Ajouter les prédictions à la liste\n        predictions.append(y_pred)\n\n# Convertir la liste des prédictions en un seul tensor\npredictions_tensor = torch.cat(predictions, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:27:23.806341Z","iopub.execute_input":"2025-03-10T15:27:23.806782Z","iopub.status.idle":"2025-03-10T15:29:24.785541Z","shell.execute_reply.started":"2025-03-10T15:27:23.806746Z","shell.execute_reply":"2025-03-10T15:29:24.784841Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"print(len(data_for_target), len(predictions_tensor.cpu().numpy()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:24.786597Z","iopub.execute_input":"2025-03-10T15:29:24.786886Z","iopub.status.idle":"2025-03-10T15:29:24.792052Z","shell.execute_reply.started":"2025-03-10T15:29:24.786855Z","shell.execute_reply":"2025-03-10T15:29:24.791307Z"}},"outputs":[{"name":"stdout","text":"79275 79275\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"data_for_target.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:24.793668Z","iopub.execute_input":"2025-03-10T15:29:24.793933Z","iopub.status.idle":"2025-03-10T15:29:24.819167Z","shell.execute_reply.started":"2025-03-10T15:29:24.793912Z","shell.execute_reply":"2025-03-10T15:29:24.818420Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"       patient_id  cohort  sexM  gene  age_at_diagnosis   age   ledd  \\\n61660           0       0     1     2              54.5  58.2  497.0   \n61661           0       0     1     2              54.5  59.0  549.0   \n61662           0       0     1     2              54.5  59.6  581.0   \n\n       time_since_intake_on  time_since_intake_off    on        off  \\\n61660                   3.7              14.310491  17.0  36.244167   \n61661                   2.9              14.344101  11.0  29.071857   \n61662                   1.1              14.500000  29.0  43.000000   \n\n       on_off_ratio  off_cumavg  on_cumavg   off_lag1    on_lag1   off_ewma  \\\n61660      0.456447   36.244167       17.0  22.000000   7.004841  36.244167   \n61661      0.365791   32.658012       14.0  36.244167  17.000000  31.462627   \n61662      0.659091   36.105341       19.0  29.071857  11.000000  39.154209   \n\n       index_measure  \n61660              1  \n61661              2  \n61662              3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>sexM</th>\n      <th>gene</th>\n      <th>age_at_diagnosis</th>\n      <th>age</th>\n      <th>ledd</th>\n      <th>time_since_intake_on</th>\n      <th>time_since_intake_off</th>\n      <th>on</th>\n      <th>off</th>\n      <th>on_off_ratio</th>\n      <th>off_cumavg</th>\n      <th>on_cumavg</th>\n      <th>off_lag1</th>\n      <th>on_lag1</th>\n      <th>off_ewma</th>\n      <th>index_measure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>61660</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>58.2</td>\n      <td>497.0</td>\n      <td>3.7</td>\n      <td>14.310491</td>\n      <td>17.0</td>\n      <td>36.244167</td>\n      <td>0.456447</td>\n      <td>36.244167</td>\n      <td>17.0</td>\n      <td>22.000000</td>\n      <td>7.004841</td>\n      <td>36.244167</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>61661</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>59.0</td>\n      <td>549.0</td>\n      <td>2.9</td>\n      <td>14.344101</td>\n      <td>11.0</td>\n      <td>29.071857</td>\n      <td>0.365791</td>\n      <td>32.658012</td>\n      <td>14.0</td>\n      <td>36.244167</td>\n      <td>17.000000</td>\n      <td>31.462627</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>61662</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>54.5</td>\n      <td>59.6</td>\n      <td>581.0</td>\n      <td>1.1</td>\n      <td>14.500000</td>\n      <td>29.0</td>\n      <td>43.000000</td>\n      <td>0.659091</td>\n      <td>36.105341</td>\n      <td>19.0</td>\n      <td>29.071857</td>\n      <td>11.000000</td>\n      <td>39.154209</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"# Ajouter les prédictions au DataFrame\ndata_for_target[\"estimated_target\"] = predictions_tensor.cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:24.820262Z","iopub.execute_input":"2025-03-10T15:29:24.820517Z","iopub.status.idle":"2025-03-10T15:29:24.832160Z","shell.execute_reply.started":"2025-03-10T15:29:24.820494Z","shell.execute_reply":"2025-03-10T15:29:24.831387Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"data_for_target = data_for_target.sort_index()\ndata_for_target.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:24.833024Z","iopub.execute_input":"2025-03-10T15:29:24.833302Z","iopub.status.idle":"2025-03-10T15:29:24.868389Z","shell.execute_reply.started":"2025-03-10T15:29:24.833273Z","shell.execute_reply":"2025-03-10T15:29:24.867516Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"   patient_id  cohort  sexM  gene  age_at_diagnosis   age   ledd  \\\n0        3332       0     0     1              48.5  52.1  607.0   \n1        3332       0     0     1              48.5  53.0  666.0   \n2        3332       0     0     1              48.5  53.9  717.0   \n\n   time_since_intake_on  time_since_intake_off    on        off  on_off_ratio  \\\n0                   1.9              14.779859   7.0  38.620296      0.176677   \n1                   1.9              17.600000  12.0  44.000000      0.266667   \n2                   1.2              14.878010   6.0  39.662327      0.147557   \n\n   off_cumavg  on_cumavg   off_lag1  on_lag1   off_ewma  index_measure  \\\n0   38.620296   7.000000  30.000000     13.0  38.620296              1   \n1   41.310148   9.500000  38.620296      7.0  42.206765              2   \n2   40.760874   8.333333  44.000000     12.0  40.510473              3   \n\n   estimated_target  \n0        117.991959  \n1        143.792313  \n2        143.668640  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>cohort</th>\n      <th>sexM</th>\n      <th>gene</th>\n      <th>age_at_diagnosis</th>\n      <th>age</th>\n      <th>ledd</th>\n      <th>time_since_intake_on</th>\n      <th>time_since_intake_off</th>\n      <th>on</th>\n      <th>off</th>\n      <th>on_off_ratio</th>\n      <th>off_cumavg</th>\n      <th>on_cumavg</th>\n      <th>off_lag1</th>\n      <th>on_lag1</th>\n      <th>off_ewma</th>\n      <th>index_measure</th>\n      <th>estimated_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>48.5</td>\n      <td>52.1</td>\n      <td>607.0</td>\n      <td>1.9</td>\n      <td>14.779859</td>\n      <td>7.0</td>\n      <td>38.620296</td>\n      <td>0.176677</td>\n      <td>38.620296</td>\n      <td>7.000000</td>\n      <td>30.000000</td>\n      <td>13.0</td>\n      <td>38.620296</td>\n      <td>1</td>\n      <td>117.991959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>48.5</td>\n      <td>53.0</td>\n      <td>666.0</td>\n      <td>1.9</td>\n      <td>17.600000</td>\n      <td>12.0</td>\n      <td>44.000000</td>\n      <td>0.266667</td>\n      <td>41.310148</td>\n      <td>9.500000</td>\n      <td>38.620296</td>\n      <td>7.0</td>\n      <td>42.206765</td>\n      <td>2</td>\n      <td>143.792313</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3332</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>48.5</td>\n      <td>53.9</td>\n      <td>717.0</td>\n      <td>1.2</td>\n      <td>14.878010</td>\n      <td>6.0</td>\n      <td>39.662327</td>\n      <td>0.147557</td>\n      <td>40.760874</td>\n      <td>8.333333</td>\n      <td>44.000000</td>\n      <td>12.0</td>\n      <td>40.510473</td>\n      <td>3</td>\n      <td>143.668640</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"data_for_target.to_csv('data_with_estimated_target.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:29:24.869117Z","iopub.execute_input":"2025-03-10T15:29:24.869355Z","iopub.status.idle":"2025-03-10T15:29:25.821343Z","shell.execute_reply.started":"2025-03-10T15:29:24.869307Z","shell.execute_reply":"2025-03-10T15:29:25.820395Z"}},"outputs":[],"execution_count":113}]}